{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Model Evaluation Lab\n",
    "\n",
    "Complete the exercises below to solidify your knowledge and understanding of supervised learning model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, precision_score , recall_score, f1_score, fbeta_score\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.linear_model import SGDRegressor, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "data = load_boston()\n",
    "\n",
    "X = pd.DataFrame(data[\"data\"], columns=data[\"feature_names\"])\n",
    "y = pd.DataFrame(data[\"target\"], columns=['MEDV'])\n",
    "\n",
    "data = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split this data set into training (80%) and testing (20%) sets.\n",
    "\n",
    "The `MEDV` field represents the median value of owner-occupied homes (in $1000's) and is the target variable that we will want to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos las 4 variables con las que trabajar, y el train test nos divide el dataset en 4 partes, 2( features y target) para entrenar y 2 para testear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train a `LinearRegression` model on this data set and generate predictions on both the training and the testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llamamos a la funcion, entrenamos y predecimos, primero con el test ( se hace al revés), y luego con con el train. Nos da una lista de valores que serías las predicciones realizadas, la lista lógicamente tiene el mismo tamaño que los datos que le hemos dado en cada predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_model=LinearRegression()\n",
    "boston_model.fit (X_train, y_train)\n",
    "y_pred= boston_model.predict (X_test)\n",
    "y_pred2=boston_model.predict (X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate and print R-squared for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2:  0.7220257852231711\n",
      "R2:  0.7434933749635788\n"
     ]
    }
   ],
   "source": [
    "print(\"R2: \", metrics.r2_score(y_test,y_pred))\n",
    "print(\"R2: \", metrics.r2_score(y_train,y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate and print mean squared error for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  4.929032572806593\n",
      "RMSE:  4.632477865964201\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE: \", np.sqrt(metrics.mean_squared_error(y_test,y_pred)))\n",
    "print(\"RMSE: \", np.sqrt(metrics.mean_squared_error(y_train,y_pred2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculate and print mean absolute error for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  3.295378517851354\n",
      "MAE:  3.2654576160766533\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE: \", metrics.mean_absolute_error(y_test, y_pred))\n",
    "print(\"MAE: \", metrics.mean_absolute_error(y_train, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris()\n",
    "\n",
    "X = pd.DataFrame(data[\"data\"], columns=data[\"feature_names\"])\n",
    "y = pd.DataFrame(data[\"target\"], columns=[\"class\"])\n",
    "\n",
    "data = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Split this data set into training (80%) and testing (20%) sets.\n",
    "\n",
    "The `class` field represents the type of flower and is the target variable that we will want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train a `LogisticRegression` model on this data set and generate predictions on both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asiok\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "LRiris_model = LogisticRegression(max_iter=100000)\n",
    "LRiris_model.fit (X_train,y_train)\n",
    "y_pred=LRiris_model.predict (X_train)\n",
    "y_pred2=LRiris_model.predict (X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Calculate and print the accuracy score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "% de acierto de la prediccion sobre lo real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.975\n",
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "print (accuracy_score(y_train, y_pred))\n",
    "print (accuracy_score (y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Calculate and print the balanced accuracy score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9751540449214868\n",
      "0.9220779220779222\n"
     ]
    }
   ],
   "source": [
    "print (balanced_accuracy_score(y_train, y_pred))\n",
    "print (balanced_accuracy_score(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Calculate and print the precision score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es el porcentaje de acierto sobre mis propias previsiones, es decir, el 100% de los positivos han acertado para el 0, el 97 y 100 para el 1 y el 97 y 84 para el 2. En este caso lo que \"queda fuera\", (1-precision_score) son nuestros falsos positivos. (los numeros han variado despúes de reiniciar kernel y obtener un train/test diferente)\n",
    "\n",
    "Resultado de dividir nuestros flores x coincidentes con las reales entre todas las flores que hemos dicho que son x.\n",
    "\n",
    "Voy a sacar todos los valores del parámetro average y así los veo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.975\n",
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "print (precision_score(y_train, y_pred, average=\"micro\"))\n",
    "print (precision_score(y_test, y_pred2, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9760765550239235\n",
      "0.9220779220779222\n"
     ]
    }
   ],
   "source": [
    "print (precision_score(y_train, y_pred, average=\"macro\"))\n",
    "print (precision_score(y_test, y_pred2, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9751594896331739\n",
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "print (precision_score(y_train, y_pred, average=\"weighted\"))\n",
    "print (precision_score(y_test, y_pred2, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.97368421 0.95454545]\n",
      "[1.         0.90909091 0.85714286]\n"
     ]
    }
   ],
   "source": [
    "print (precision_score(y_train, y_pred, average=None))\n",
    "print (precision_score(y_test, y_pred2, average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acertadas de la flor 1, entre las que hemos dicho que eran 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "37/38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Calculate and print the recall score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positivos correctamente sobre el total de positivos, para el 0, el 1 y el 2, es decir, para clase 0, nuestro modelo acierta los positivos en el 100% de los casos, para la clase 1, los acierta en 97 y 94 y para la clase 2 en un 97 y 100. En este caso lo que \"queda fuera\", (1 - recall_score), son los positivos reales que no hemos acertado, los falsos negativos.\n",
    "\n",
    "En otras palabras, es el resultado de dividir los positivos acertados en la predicción entre los positivos reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.975\n",
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "print (recall_score(y_train, y_pred, average= \"micro\"))\n",
    "print (recall_score(y_test, y_pred2, average= \"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9751540449214868\n",
      "0.9220779220779222\n"
     ]
    }
   ],
   "source": [
    "print (recall_score(y_train, y_pred, average= \"macro\"))\n",
    "print (recall_score(y_test, y_pred2, average= \"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.975\n",
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "print (recall_score(y_train, y_pred, average= \"weighted\"))\n",
    "print (recall_score(y_test, y_pred2, average= \"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.94871795 0.97674419]\n",
      "[1.         0.90909091 0.85714286]\n"
     ]
    }
   ],
   "source": [
    "print (recall_score(y_train, y_pred, average=None))\n",
    "print (recall_score(y_test, y_pred2, average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acertadas de la clase 1, entre las que realmente eran 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9487179487179487"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "37/39 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Calculate and print the F1 score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Media armónica de recall y precision, es decir: 2/(1/recall) +(1/precission), esta media tiende dar mayor peso a los valores inferiores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.975\n",
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "print (f1_score(y_train, y_pred, average=\"micro\"))\n",
    "print (f1_score(y_test, y_pred2, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9755187341394239\n",
      "0.9220779220779222\n"
     ]
    }
   ],
   "source": [
    "print (f1_score(y_train, y_pred, average=\"macro\"))\n",
    "print (f1_score(y_test, y_pred2, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.974981340498582\n",
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "print (f1_score(y_train, y_pred, average=\"weighted\"))\n",
    "print (f1_score(y_test, y_pred2, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.97368421 0.95454545]\n",
      "[1.         0.90909091 0.85714286]\n"
     ]
    }
   ],
   "source": [
    "print (precision_score(y_train, y_pred, average=None))\n",
    "print (precision_score(y_test, y_pred2, average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la vista inferior el resumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.        , 0.97368421, 0.95454545]),\n",
       " array([1.        , 0.94871795, 0.97674419]),\n",
       " array([1.        , 0.96103896, 0.96551724]),\n",
       " array([38, 39, 43], dtype=int64))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support (y_train, y_pred, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.        , 0.90909091, 0.85714286]),\n",
       " array([1.        , 0.90909091, 0.85714286]),\n",
       " array([1.        , 0.90909091, 0.85714286]),\n",
       " array([12, 11,  7], dtype=int64))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support (y_test, y_pred2, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        38\n",
      "           1       0.97      0.95      0.96        39\n",
      "           2       0.95      0.98      0.97        43\n",
      "\n",
      "    accuracy                           0.97       120\n",
      "   macro avg       0.98      0.98      0.98       120\n",
      "weighted avg       0.98      0.97      0.97       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report (y_train, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       0.91      0.91      0.91        11\n",
      "           2       0.86      0.86      0.86         7\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.92      0.92      0.92        30\n",
      "weighted avg       0.93      0.93      0.93        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report (y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se aprecia que los porcentajes de acierto bajan en el test frente a los obtenidos en sobre los datos entrenados. Sería significativo y podríamos decir que hay cierto overfitting en nuestro modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Generate confusion matrices for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[38,  0,  0],\n",
       "       [ 0, 37,  2],\n",
       "       [ 0,  1, 42]], dtype=int64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "resumen: fila 0= flores 0 reales; flores 0 que hemos dicho que eran 1; flores 0 que hemos dicho que eran 2\n",
    "         fila 1= flores 1 que hemos dicho que eran 0; flores 1 que hemos dicho que eran 1; flores 2 que hemos dicho que eran 2\n",
    "         fila 2= flores 2 que hemos dicho que eran 0, flores 2 que hemos dicho que eran 1; flores 2 que hemos dicho que eran 2\n",
    "suma de las columnas= cantidad real/support\n",
    "suma de las filas= nuestra prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disculpadme que lo ponga así, está pensado por si lo necesito entender otra vez dentro de 3 años xd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12,  0,  0],\n",
       "       [ 0, 10,  1],\n",
       "       [ 0,  1,  6]], dtype=int64)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y aquí vemos porque nos daba el mismo resultado en recall y precission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: For each of the data sets in this lab, try training with some of the other models you have learned about, recalculate the evaluation metrics, and compare to determine which models perform best on each data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos con el primer data, nos encontramos ante un problema de regresión, por lo que usaremos esos modelos. La diferencia, por lo que hemos visto hasta ahora creo que la podemos simplificar a:\n",
    "* regresión: predecimos un valor numérico sin rango ( Pe: si eres rubio, trabajas y tienes 3 hermanos: ganarás x dinero)\n",
    "* clasificación: predecimos un valor categórico que puede ser clasificado por numeros ( Pe: si eres rubio, trabajas y tienes 3 hermanos: eres ejecutivo) \n",
    "\n",
    "De lo que también se deduce que las [métricas que utilicemos](https://fayrix.com/machine-learning-metrics_es) no pueden ser las mismas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "data = load_boston()\n",
    "\n",
    "X = pd.DataFrame(data[\"data\"], columns=data[\"feature_names\"])\n",
    "y = pd.DataFrame(data[\"target\"], columns=['MEDV'])\n",
    "\n",
    "data = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos un diccionario que llama a distintos modelos, después iteramos sobre el para entrenarlo primero, y printear metricas para ytrain e ytest después. Con esto echaremos un vistazo rápido a varios modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_models= { \"Linnear\":LinearRegression (),\n",
    "                 \"ridge\": Ridge(),\n",
    "                 \"laso\": Lasso(),\n",
    "                 \"sgd\": SGDRegressor (),\n",
    "                 \"knn\": KNeighborsRegressor(),\n",
    "                 \"gradient\": GradientBoostingRegressor ()\n",
    "                 \n",
    "    \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in boston_models.items():\n",
    "    model.fit(X_train,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[values.ravel error](https://stackoverflow.com/questions/34165731/a-column-vector-y-was-passed-when-a-1d-array-was-expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Linneartest--------\n",
      "MAE:  3.2716385742562473\n",
      "MSE:  24.554792940076364\n",
      "RMSE:  4.955279299905946\n",
      "R2:  0.6776857673620341\n",
      "\n",
      "\n",
      "--------Linneartrain--------\n",
      "MAE:  3.3517643226774454\n",
      "MSE:  21.452677426234516\n",
      "RMSE:  4.631703512341276\n",
      "R2:  0.7519664132413573\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------ridgetest--------\n",
      "MAE:  3.276701864031989\n",
      "MSE:  24.75912343694789\n",
      "RMSE:  4.975854040960997\n",
      "R2:  0.6750036585181761\n",
      "\n",
      "\n",
      "--------ridgetrain--------\n",
      "MAE:  3.3348425108588557\n",
      "MSE:  21.63411941426411\n",
      "RMSE:  4.651249231578986\n",
      "R2:  0.7498686001719004\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------lasotest--------\n",
      "MAE:  3.733442390489292\n",
      "MSE:  29.692599301946128\n",
      "RMSE:  5.449091603372633\n",
      "R2:  0.6102452428579264\n",
      "\n",
      "\n",
      "--------lasotrain--------\n",
      "MAE:  3.630613422815236\n",
      "MSE:  26.22711643795852\n",
      "RMSE:  5.121241689078785\n",
      "R2:  0.6967648545123706\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------sgdtest--------\n",
      "MAE:  39941849867502.14\n",
      "MSE:  1.8321181010352744e+27\n",
      "RMSE:  42803248720573.47\n",
      "R2:  -2.4048980631944812e+25\n",
      "\n",
      "\n",
      "--------sgdtrain--------\n",
      "MAE:  42469105418114.95\n",
      "MSE:  2.0534295376828826e+27\n",
      "RMSE:  45314782772103.0\n",
      "R2:  -2.3741535066610336e+25\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------knntest--------\n",
      "MAE:  3.8333333333333335\n",
      "MSE:  30.666980392156866\n",
      "RMSE:  5.5377775679560175\n",
      "R2:  0.5974551983988\n",
      "\n",
      "\n",
      "--------knntrain--------\n",
      "MAE:  3.6149504950495053\n",
      "MSE:  26.94896237623762\n",
      "RMSE:  5.191239002033871\n",
      "R2:  0.6884189481436125\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------gradienttest--------\n",
      "MAE:  2.1223205810251873\n",
      "MSE:  7.302785118211624\n",
      "RMSE:  2.702366577319151\n",
      "R2:  0.9041412571777517\n",
      "\n",
      "\n",
      "--------gradienttrain--------\n",
      "MAE:  1.0979484258781012\n",
      "MSE:  1.909243180213312\n",
      "RMSE:  1.381753661190486\n",
      "R2:  0.9779255323438709\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model in boston_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred2= model.predict (X_train)\n",
    "    print(f\"--------{name}test--------\")\n",
    "    print(\"MAE: \", metrics.mean_absolute_error(y_test, y_pred))\n",
    "    print(\"MSE: \", metrics.mean_squared_error(y_test,y_pred))\n",
    "    print(\"RMSE: \", np.sqrt(metrics.mean_squared_error(y_test,y_pred)))\n",
    "    print(\"R2: \", metrics.r2_score(y_test,y_pred))\n",
    "    print(\"\\n\")\n",
    "    print(f\"--------{name}train--------\")\n",
    "    print(\"MAE: \", metrics.mean_absolute_error(y_train, y_pred2))\n",
    "    print(\"MSE: \", metrics.mean_squared_error(y_train,y_pred2))\n",
    "    print(\"RMSE: \", np.sqrt(metrics.mean_squared_error(y_train,y_pred2)))\n",
    "    print(\"R2: \", metrics.r2_score(y_train,y_pred2))\n",
    "    print(\"\\n\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos claramente que el [gradientboosting](https://interactivechaos.com/es/manual/tutorial-de-machine-learning/gradient-boosting) tiene un R2 lo suficientemente destacado como para elegirlo a simple vista. En cualquier caso, por seguir indagando vamos a imaginarnos que tenemos unos resultados ajustados, para ello utilizaré el cross validation, que sencillamente hace tanto splits como le digamos ( en este caso 5) con la particularidad de qué, aún siendo aleatorios, no se repiten los datos en los splits. Y nos devuelve un r2 para cada split. Es meramente informativo, pero es muy util porque el split inicial por lo que sea puede estar mal balanceado.\n",
    "\n",
    "Seguimos iterando por el diccionario de modelos, y le pedimos la media de los r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linnear r2 0.7261800329428449\n",
      "ridge r2 0.7257207244999027\n",
      "laso r2 0.6756914036919176\n",
      "sgd r2 -4.6930600694861196e+26\n",
      "knn r2 0.48885187027281435\n",
      "gradient r2 0.8611459136563401\n"
     ]
    }
   ],
   "source": [
    "for name, model in boston_models.items():\n",
    "    scores = cross_val_score(model, X_train, y_train.values.ravel(), scoring = \"r2\", cv=5)\n",
    "    print(f\"{name} r2 {np.mean(scores)}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos sacar conclusiones interesantes sobre la utilidad del cross validation, como vemos gradient ha bajado en 4 puntos y linnear y ridge han subido en 5. Para nuestro caso es irrelevante porque la diferencia era enorme, pero sí que es cierto que en otros casos nos podemos encontrar con una diferencia de 10-15 puntos que puede darse la vuelta al hacer este proceso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos con el segundo data, en este caso de clasificación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris()\n",
    "\n",
    "X = pd.DataFrame(data[\"data\"], columns=data[\"feature_names\"])\n",
    "y = pd.DataFrame(data[\"target\"], columns=[\"class\"])\n",
    "\n",
    "data = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y hasta aquí, el otro data para otro día"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
